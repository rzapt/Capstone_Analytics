{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Scrape data tables from capstone courier and write into an excle file (one table per sheet) for ease of analysis\n",
    "\n",
    "*Input Round Below, Then Run All !!!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = \"6\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_path = \"C:\\\\Users\\\\rzapp\\\\OneDrive - University of Cincinnati\\\\Capsim Ferris-40 Documents\\\\Capstone Couriers\\\\Courier_Round_\" + round + \".htm\"\n",
    "ending_file_path = 'C:\\\\Users\\\\rzapp\\OneDrive - University of Cincinnati\\\\Capsim Ferris-40 Documents\\\\Capstone Couriers\\\\Courier_Data_Round_' + round + '.xlsx'\n",
    "list_of_dfs = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Parse HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read html file contents and transfer into variable\n",
    "with open(html_path,\"r\") as file:\n",
    "    html_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse html\n",
    "soup = BeautifulSoup(html_contents,'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate HTML Data Into Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Financial Statements, Production Information, and Segment Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific function to convert main tables into data frame\n",
    "def html_To_DF_Main_Tables(table_results):\n",
    "    \n",
    "    try:\n",
    "        for i in enumerate(table_results):\n",
    "            if i[0] >= 3:\n",
    "                df = pd.read_html(str(i[1]))[0]\n",
    "                df.columns = df.iloc[0]\n",
    "                df = df[1:]\n",
    "                list_of_dfs.append(df.fillna(\"\"))\n",
    "            else:    \n",
    "                df = pd.read_html(str(i[1]))[0]\n",
    "                list_of_dfs.append(df.fillna(\"\"))\n",
    "\n",
    "    except Exception:\n",
    "        print(Exception)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull financial statements, production  information, and segment product information    \n",
    "table_results = soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'655','cellspacing':'0','cellpadding':'1','border':'0'})\n",
    "html_To_DF_Main_Tables(table_results = table_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Market Share Report, Financial Statistics, Stock Market, HR, TQM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Df_To_List(dataFrame):\n",
    "    \n",
    "    try:\n",
    "        dataFrame.columns = dataFrame.fillna(\"\").iloc[0]\n",
    "        dataFrame = dataFrame[1:].fillna(\"\")\n",
    "        list_of_dfs.append(dataFrame)\n",
    "\n",
    "    except Exception:\n",
    "        print(\"DataFrame not added to list, error:\",Exception)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Actual Market Share (AMS) & Potential Market Share to Dataframe, then add to list_of_dfs\n",
    "try: \n",
    "    AMS_df = pd.read_html(str(soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'305','cellspacing':'0','cellpadding':'0','border':'0'})[1]))[0]\n",
    "    PMS_df = pd.read_html(str(soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'325','cellspacing':'0','cellpadding':'0','border':'0'})[1]))[0]\n",
    "\n",
    "    Add_Df_To_List(AMS_df)\n",
    "    Add_Df_To_List(PMS_df)\n",
    "\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Statistics and Stock Market Summary\n",
    "try:    \n",
    "    fin_stats_df = pd.read_html(str(soup.find_all('table', attrs={'width':'655','cellspacing':'0','cellpadding':'1','border':'0'})[0]))[0]\n",
    "    stock_summary = pd.read_html(str(soup.find_all('table', attrs={'width':'655','cellspacing':'0','cellpadding':'1','border':'0'})[1]))[0]\n",
    "\n",
    "    Add_Df_To_List(fin_stats_df)\n",
    "    list_of_dfs.append(stock_summary)   # No manipulation needed\n",
    "\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR and TQM\n",
    "try: \n",
    "    HR_df = pd.read_html(str(soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'655','cellspacing':'0','cellpadding':'2','border':'0'})[0]))[0]\n",
    "    TQM_df = pd.read_html(str(soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'655','cellspacing':'0','cellpadding':'0','border':'0'})[0]))[0]\n",
    "\n",
    "    Add_Df_To_List(HR_df)\n",
    "    Add_Df_To_List(TQM_df)\n",
    "\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customer Buying Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gathers buying criteria\n",
    "\n",
    "def Gather_Buying_Criteria():\n",
    "    \n",
    "    try:\n",
    "        segments = ['Traditional','Low End','High End','Performance','Size']\n",
    "        attr_list = []\n",
    "        expect_list = []\n",
    "        importn_list = []\n",
    "        segment_list = []\n",
    "\n",
    "        for i in enumerate(segments):\n",
    "\n",
    "            # Create a df in a loop because I'm lazy, even though it takes up a ton of power\n",
    "            df = pd.read_html(str(soup.find_all('table', attrs={'bordercolordark':'#000000', 'width':'325','cellspacing':'0','cellpadding':'1','border':'0'})[i[0]]))[0]\n",
    "            df.columns = df.fillna(\"\").iloc[0]\n",
    "            df = df.iloc[1: , 1:].rename(columns = {\"\":\"Attribute\"})\n",
    "            df['Segment'] = i[1]\n",
    "\n",
    "            # Apply df cols to lists, then append those lists\n",
    "            attr_list += list(df['Attribute'])\n",
    "            expect_list += list(df['Expectations'])\n",
    "            importn_list += list(df['Importance'])\n",
    "            segment_list += list(df['Segment'])\n",
    "\n",
    "        zipped_lists = zip(attr_list, expect_list, importn_list, segment_list)\n",
    "        df = pd.DataFrame(zipped_lists, columns=['Attribute', 'Expectations', 'Importance','Segment'])\n",
    "        df['Round'] = round\n",
    "        \n",
    "        return(df)\n",
    "    \n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful append\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    list_of_dfs.append(Gather_Buying_Criteria())\n",
    "    print(\"successful append\")\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing DataFrames to an Excel File on SharePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['Cash Flow Statemment Survey','Balance Sheet Survey','Income Statement Survey','Production Information','Traditional',\n",
    "    'Low End','High End','Performance','Size','Actual Market Share','Potential Market Share', 'Financial Statistics','Stock Market Summary','HR','TQM','Customer Buying Criteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(ending_file_path) as writer:\n",
    "        for i in enumerate(list_of_dfs):\n",
    "                i[1].to_excel(writer, sheet_name = table_names[i[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing New Ideas:\n",
    "- Autoformat columns before excel\n",
    "- Set to autorun every (after decisions are officially plugged into system)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bb19d950a13d90740e03541420c82fb56634d833c3ccab546a0215e7b33f662"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
